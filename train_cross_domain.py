"""
å¤šæ¨¡æ€è·¨åŸŸè‡ªé€‚åº”UNetè®­ç»ƒè„šæœ¬
æ­£ç¡®çš„ä»£ç ç»„ç»‡ç»“æ„
"""
import logging
import torch
import torch.nn as nn
import torch.nn.functional as F
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import numpy as np
from PIL import Image
import random
import time
from datetime import datetime
import matplotlib.pyplot as plt
import warnings
from mmwhs_dataset import create_mmwhs_loaders
warnings.filterwarnings('ignore')


# ==================== 1. æ¢¯åº¦åè½¬å±‚ï¼ˆæœ€åŸºç¡€çš„å·¥å…·ï¼‰ ====================
class GradientReversalLayer(torch.autograd.Function):
    """æ¢¯åº¦åè½¬å±‚"""
    @staticmethod
    def forward(ctx, x, lambda_):
        ctx.lambda_ = lambda_
        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        return grad_output.neg() * ctx.lambda_, None


# ==================== 2. UNetåŸºç¡€ç»„ä»¶ ====================
class DoubleConv(nn.Module):
    """åŒå·ç§¯å±‚"""
    def __init__(self, in_channels, out_channels, mid_channels=None):
        super().__init__()
        if not mid_channels:
            mid_channels = out_channels
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(mid_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class Down(nn.Module):
    """ä¸‹é‡‡æ ·"""
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.maxpool_conv = nn.Sequential(
            nn.MaxPool2d(2),
            DoubleConv(in_channels, out_channels)
        )

    def forward(self, x):
        return self.maxpool_conv(x)


class Up(nn.Module):
    """ä¸Šé‡‡æ ·æ¨¡å—ï¼ˆæœ€ç»ˆä¿®å¤ç‰ˆï¼‰"""

    def __init__(self, in_channels, out_channels, bilinear=True):
        super().__init__()

        if bilinear:
            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)
            # ğŸ”¥ æ‹¼æ¥åé€šé“æ•° = in_channels(ä¸‹å±‚ä¸Šé‡‡æ ·) + out_channels(è·³è·ƒè¿æ¥)
            # ä½†ä¸Šé‡‡æ ·å‰in_channelsé€šé“ä¼šå‡åŠ
            self.conv = DoubleConv(in_channels, out_channels)
        else:
            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)
            self.conv = DoubleConv(in_channels, out_channels)

    def forward(self, x1, x2):
        """
        x1: æ¥è‡ªä¸‹å±‚ (éœ€è¦ä¸Šé‡‡æ ·)
        x2: è·³è·ƒè¿æ¥
        """
        x1 = self.up(x1)

        # å°ºå¯¸å¯¹é½
        diffY = x2.size()[2] - x1.size()[2]
        diffX = x2.size()[3] - x1.size()[3]
        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,
                        diffY // 2, diffY - diffY // 2])

        # æ‹¼æ¥
        x = torch.cat([x2, x1], dim=1)
        return self.conv(x)


# ==================== 3. æ ¸å¿ƒæ¨¡å—ï¼ˆå®Œæ•´ç‰ˆï¼‰ ====================

class SemanticAdaptiveFusion(nn.Module):
    """è¯­ä¹‰è‡ªé€‚åº”èåˆæ¨¡å—"""

    def __init__(self, channels):
        super().__init__()

        # è¯­ä¹‰ç‰¹å¾æå–
        self.ct_semantic = nn.Sequential(
            nn.Conv2d(channels, channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(channels),
            nn.ReLU(inplace=True)
        )

        self.mri_semantic = nn.Sequential(
            nn.Conv2d(channels, channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(channels),
            nn.ReLU(inplace=True)
        )

        # ç›¸ä¼¼åº¦è®¡ç®—
        self.similarity = nn.Sequential(
            nn.Conv2d(channels * 2, channels, 1, bias=False),
            nn.BatchNorm2d(channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels, 2, 1),
            nn.Softmax(dim=1)
        )

    def forward(self, ct_feat, mri_feat):
        """
        è‡ªé€‚åº”èåˆ

        Returns:
            fused: èåˆåçš„ç‰¹å¾
        """
        # è¯­ä¹‰ç‰¹å¾
        ct_sem = self.ct_semantic(ct_feat)
        mri_sem = self.mri_semantic(mri_feat)

        # è®¡ç®—ç›¸ä¼¼åº¦æƒé‡
        concat = torch.cat([ct_sem, mri_sem], dim=1)
        weights = self.similarity(concat)  # [B, 2, H, W]

        # åŠ æƒèåˆ
        ct_weight = weights[:, 0:1, :, :]
        mri_weight = weights[:, 1:2, :, :]

        fused = ct_feat * ct_weight + mri_feat * mri_weight

        return fused


class CrossDomainAlignment(nn.Module):
    """è·¨åŸŸå¯¹é½æ¨¡å—"""

    def __init__(self, channels):
        super().__init__()

        # åŸŸåˆ¤åˆ«å™¨
        self.domain_discriminator = nn.Sequential(
            nn.Conv2d(channels, channels // 2, 3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(channels // 2, 1)
        )

        # ç‰¹å¾å¯¹é½
        self.align_conv = nn.Sequential(
            nn.Conv2d(channels, channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, ct_feat, mri_feat):
        """
        è·¨åŸŸå¯¹é½

        Returns:
            ct_aligned: å¯¹é½åçš„CTç‰¹å¾
            mri_aligned: å¯¹é½åçš„MRIç‰¹å¾
            domain_loss: åŸŸå¯¹æŠ—æŸå¤±
        """
        # ç‰¹å¾å¯¹é½
        ct_aligned = self.align_conv(ct_feat)
        mri_aligned = self.align_conv(mri_feat)

        if self.training:
            # æ¢¯åº¦åè½¬
            ct_reversed = GradientReversalLayer.apply(ct_aligned, 1.0)
            mri_reversed = GradientReversalLayer.apply(mri_aligned, 1.0)

            # åŸŸåˆ¤åˆ«
            ct_domain_pred = self.domain_discriminator(ct_reversed)
            mri_domain_pred = self.domain_discriminator(mri_reversed)

            # åŸŸå¯¹æŠ—æŸå¤±
            ct_labels = torch.zeros_like(ct_domain_pred)
            mri_labels = torch.ones_like(mri_domain_pred)

            bce_loss = nn.BCEWithLogitsLoss()
            domain_loss = (bce_loss(ct_domain_pred, ct_labels) +
                           bce_loss(mri_domain_pred, mri_labels)) / 2
        else:
            domain_loss = torch.tensor(0.0, device=ct_feat.device)

        return ct_aligned, mri_aligned, domain_loss


class MultiModalPriorMask(nn.Module):
    """å¤šæ¨¡æ€å…ˆéªŒæ©ç ç”Ÿæˆå™¨"""

    def __init__(self, channels):
        super().__init__()

        self.prior_net = nn.Sequential(
            nn.Conv2d(channels * 2, channels, 3, padding=1, bias=False),
            nn.BatchNorm2d(channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels, channels // 2, 3, padding=1, bias=False),
            nn.BatchNorm2d(channels // 2),
            nn.ReLU(inplace=True),
            nn.Conv2d(channels // 2, 1, 1),
            nn.Sigmoid()
        )

    def forward(self, ct_feat, mri_feat):
        """
        ç”Ÿæˆå…ˆéªŒæ©ç 

        Returns:
            prior: å…ˆéªŒæ©ç  [B, 1, H, W]
        """
        concat = torch.cat([ct_feat, mri_feat], dim=1)
        prior = self.prior_net(concat)
        return prior


class OutConv(nn.Module):
    """è¾“å‡ºå·ç§¯å±‚"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)

    def forward(self, x):
        return self.conv(x)


# ==================== 4. å®Œæ•´æ¨¡å‹ ====================
class MultiModalCrossDomainUNet(nn.Module):
    """å¤šæ¨¡æ€è·¨åŸŸè‡ªé€‚åº”UNet - å®Œæ•´ç‰ˆ"""

    def __init__(self, n_classes=2, bilinear=True, base_channels=64):
        super().__init__()
        self.n_classes = n_classes
        self.bilinear = bilinear

        # CTç¼–ç å™¨
        self.ct_inc = DoubleConv(1, base_channels)
        self.ct_down1 = Down(base_channels, base_channels * 2)
        self.ct_down2 = Down(base_channels * 2, base_channels * 4)
        self.ct_down3 = Down(base_channels * 4, base_channels * 8)
        factor = 2 if bilinear else 1
        self.ct_down4 = Down(base_channels * 8, base_channels * 16 // factor)

        # MRIç¼–ç å™¨
        self.mri_inc = DoubleConv(1, base_channels)
        self.mri_down1 = Down(base_channels, base_channels * 2)
        self.mri_down2 = Down(base_channels * 2, base_channels * 4)
        self.mri_down3 = Down(base_channels * 4, base_channels * 8)
        self.mri_down4 = Down(base_channels * 8, base_channels * 16 // factor)

        # èåˆæ¨¡å—
        self.fusion_modules = nn.ModuleList([
            SemanticAdaptiveFusion(base_channels),
            SemanticAdaptiveFusion(base_channels * 2),
            SemanticAdaptiveFusion(base_channels * 4),
            SemanticAdaptiveFusion(base_channels * 8),
            SemanticAdaptiveFusion(base_channels * 16 // factor)
        ])

        # åŸŸå¯¹é½æ¨¡å—
        self.alignment_modules = nn.ModuleList([
            CrossDomainAlignment(base_channels),
            CrossDomainAlignment(base_channels * 2),
            CrossDomainAlignment(base_channels * 4),
            CrossDomainAlignment(base_channels * 8),
            CrossDomainAlignment(base_channels * 16 // factor)
        ])

        # å…ˆéªŒç”Ÿæˆå™¨
        self.prior_generator = MultiModalPriorMask(base_channels * 16 // factor)

        # ğŸ”¥ è§£ç å™¨ - ä¿®æ­£é€šé“æ•°è®¡ç®—
        # Up(è¾“å…¥é€šé“, è¾“å‡ºé€šé“)
        # è¾“å…¥é€šé“ = ä¸‹å±‚ç‰¹å¾ + è·³è·ƒè¿æ¥ç‰¹å¾
        self.up1 = Up(base_channels * 16 // factor + base_channels * 8, base_channels * 8 // factor, bilinear)
        self.up2 = Up(base_channels * 8 // factor + base_channels * 4, base_channels * 4 // factor, bilinear)
        self.up3 = Up(base_channels * 4 // factor + base_channels * 2, base_channels * 2 // factor, bilinear)
        self.up4 = Up(base_channels * 2 // factor + base_channels, base_channels, bilinear)

        # è¾“å‡ºå±‚
        self.ct_outc = OutConv(base_channels, n_classes)
        self.mri_outc = OutConv(base_channels, n_classes)

        # ä¿å­˜è¾“å‡º
        self.ct_output = None
        self.mri_output = None

    def forward(self, ct_img, mri_img, return_details=False):
        """å‰å‘ä¼ æ’­ - å®Œå…¨ä¿®å¤ç‰ˆ"""

        # CTç¼–ç 
        ct1 = self.ct_inc(ct_img)  # [B, 32, 256, 256]
        ct2 = self.ct_down1(ct1)  # [B, 64, 128, 128]
        ct3 = self.ct_down2(ct2)  # [B, 128, 64, 64]
        ct4 = self.ct_down3(ct3)  # [B, 256, 32, 32]
        ct5 = self.ct_down4(ct4)  # [B, 256, 16, 16]

        # MRIç¼–ç 
        mri1 = self.mri_inc(mri_img)
        mri2 = self.mri_down1(mri1)
        mri3 = self.mri_down2(mri2)
        mri4 = self.mri_down3(mri3)
        mri5 = self.mri_down4(mri4)

        # èåˆå’Œå¯¹é½
        ct_feats = [ct1, ct2, ct3, ct4, ct5]
        mri_feats = [mri1, mri2, mri3, mri4, mri5]

        total_align_loss = 0.0
        fused_feats = []

        for i, (fusion, align) in enumerate(zip(self.fusion_modules, self.alignment_modules)):
            fused = fusion(ct_feats[i], mri_feats[i])
            ct_aligned, mri_aligned, domain_loss = align(ct_feats[i], mri_feats[i])
            total_align_loss += domain_loss
            fused_feats.append(fused)

        align_loss = total_align_loss / len(self.fusion_modules)

        # ğŸ”¥ å…ˆéªŒæ©ç ç”Ÿæˆï¼ˆåº•å±‚ç‰¹å¾ï¼‰
        ct_prior_low = self.prior_generator(ct5, mri5)  # [B, 1, 16, 16]
        mri_prior_low = self.prior_generator(mri5, ct5)

        # CTè§£ç 
        ct_x = self.up1(fused_feats[4], fused_feats[3])  # 256->128
        ct_x = self.up2(ct_x, fused_feats[2])  # 128->64
        ct_x = self.up3(ct_x, fused_feats[1])  # 64->32
        ct_x = self.up4(ct_x, fused_feats[0])  # 32->32

        # MRIè§£ç 
        mri_x = self.up1(fused_feats[4], fused_feats[3])
        mri_x = self.up2(mri_x, fused_feats[2])
        mri_x = self.up3(mri_x, fused_feats[1])
        mri_x = self.up4(mri_x, fused_feats[0])

        # è¾“å‡º
        self.ct_output = self.ct_outc(ct_x)
        self.mri_output = self.mri_outc(mri_x)

        # ğŸ”¥ åˆ é™¤ prior ç”Ÿæˆå’Œ prior_loss è®¡ç®—
        # åªè¿”å›å¯¹é½æŸå¤±
        seg_loss_ct = torch.tensor(0.0, device=ct_img.device)
        seg_loss_mri = torch.tensor(0.0, device=mri_img.device)
        prior_loss = torch.tensor(0.0, device=ct_img.device)

        # ğŸ”¥ åªè¿”å› prior_loss å’Œ align_lossï¼Œseg_lossåœ¨å¤–éƒ¨è®¡ç®—
        return seg_loss_ct, seg_loss_mri, prior_loss, align_loss

# ==================== 5. æŸå¤±å‡½æ•° ====================
class DiceLoss(nn.Module):
    """DiceæŸå¤±"""
    def __init__(self, n_classes):
        super().__init__()
        self.n_classes = n_classes

    def forward(self, input, target):
        smooth = 1e-5
        input_soft = F.softmax(input, dim=1)
        target_one_hot = F.one_hot(target, self.n_classes).permute(0, 3, 1, 2).float()

        dice_per_class = []
        for i in range(self.n_classes):
            input_i = input_soft[:, i, :, :]
            target_i = target_one_hot[:, i, :, :]

            intersection = (input_i * target_i).sum()
            union = input_i.sum() + target_i.sum()

            dice = (2. * intersection + smooth) / (union + smooth)
            dice_per_class.append(dice)

        return 1 - torch.mean(torch.stack(dice_per_class))


class LabelSmoothingCrossEntropy(nn.Module):
    """æ ‡ç­¾å¹³æ»‘äº¤å‰ç†µæŸå¤±"""

    def __init__(self, smoothing=0.1):
        super().__init__()
        self.smoothing = smoothing

    def forward(self, pred, target):
        """
        Args:
            pred: [B, C, H, W] - é¢„æµ‹logits
            target: [B, H, W] - çœŸå®æ ‡ç­¾ï¼ˆæ•´æ•°ï¼‰
        """
        n_classes = pred.size(1)
        log_preds = F.log_softmax(pred, dim=1)

        # One-hotç¼–ç 
        target_one_hot = torch.zeros_like(log_preds).scatter(1, target.unsqueeze(1), 1)

        # æ ‡ç­¾å¹³æ»‘
        target_smooth = target_one_hot * (1 - self.smoothing) + self.smoothing / n_classes

        # è®¡ç®—æŸå¤±
        loss = (-target_smooth * log_preds).sum(dim=1).mean()
        return loss

class MultiModalCrossDomainLoss(nn.Module):
    def __init__(self, n_classes, seg_weight=1.0, prior_weight=0.3, align_weight=0.01):
        super().__init__()
        self.seg_weight = seg_weight
        self.prior_weight = prior_weight
        self.align_weight = 0.01  # â† æ”¹ä¸º0.01ï¼ˆå‡å°‘10å€ï¼‰

        self.ce_loss = nn.CrossEntropyLoss()
        self.dice_loss = DiceLoss(n_classes)

    def forward(self, outputs, target):
        """
        è®¡ç®—å¤šä»»åŠ¡æŸå¤±
        """
        # 1. ä¸»åˆ†å‰²æŸå¤±ï¼ˆå·²ç»æ˜¯åŸå§‹å°ºå¯¸ï¼‰
        seg_ce = self.ce_loss(outputs['segmentation'], target)
        seg_dice = self.dice_loss(outputs['segmentation'], target)
        seg_loss = 0.4 * seg_ce + 0.6 * seg_dice

        # ğŸ”¥ ä¿®å¤ï¼šå°†å…ˆéªŒæ©ç ä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
        fused_prior = outputs['prior_masks']['fused_prior']
        ct_prior = outputs['prior_masks']['ct_prior']
        mri_prior = outputs['prior_masks']['mri_prior']

        # ä¸Šé‡‡æ ·åˆ°å’Œtargetç›¸åŒçš„å°ºå¯¸
        target_size = target.shape[-2:]  # (H, W)

        fused_prior_upsampled = F.interpolate(
            fused_prior,
            size=target_size,
            mode='bilinear',
            align_corners=True
        )

        ct_prior_upsampled = F.interpolate(
            ct_prior,
            size=target_size,
            mode='bilinear',
            align_corners=True
        )

        mri_prior_upsampled = F.interpolate(
            mri_prior,
            size=target_size,
            mode='bilinear',
            align_corners=True
        )

        # 2. å…ˆéªŒæ©ç ç›‘ç£æŸå¤±ï¼ˆä½¿ç”¨ä¸Šé‡‡æ ·åçš„æ©ç ï¼‰
        prior_ce = self.ce_loss(fused_prior_upsampled, target)
        prior_dice = self.dice_loss(fused_prior_upsampled, target)
        prior_loss = 0.4 * prior_ce + 0.6 * prior_dice

        # 3. CTå’ŒMRIå„è‡ªçš„å…ˆéªŒæŸå¤±
        ct_prior_loss = self.dice_loss(ct_prior_upsampled, target)
        mri_prior_loss = self.dice_loss(mri_prior_upsampled, target)

        # 4. åŸŸå¯¹é½æŸå¤±
        alignment_losses = outputs['alignment_losses']
        alignment_loss = sum(alignment_losses) / len(alignment_losses)

        # 5. æ€»æŸå¤±
        total_loss = (
                self.seg_weight * seg_loss +
                self.prior_weight * (prior_loss + 0.2 * ct_prior_loss + 0.2 * mri_prior_loss) +
                self.align_weight * alignment_loss
        )

        return {
            'total_loss': total_loss,
            'seg_loss': seg_loss,
            'prior_loss': prior_loss,
            'alignment_loss': alignment_loss,
            'seg_ce': seg_ce,
            'seg_dice': seg_dice
        }


class BoundaryLoss(nn.Module):
    """è¾¹ç•ŒæŸå¤±ï¼ˆæé«˜IoUï¼‰"""

    def __init__(self):
        super().__init__()

    def forward(self, pred, target):
        """
        Args:
            pred: [B, 2, H, W] - é¢„æµ‹logits
            target: [B, H, W] - çœŸå®æ ‡ç­¾
        """
        # Sobelç®—å­
        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]],
                               dtype=pred.dtype, device=pred.device).view(1, 1, 3, 3)
        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]],
                               dtype=pred.dtype, device=pred.device).view(1, 1, 3, 3)

        # é¢„æµ‹è¾¹ç•Œ
        pred_prob = torch.softmax(pred, dim=1)[:, 1:2, :, :]  # [B, 1, H, W]
        pred_edge_x = F.conv2d(pred_prob, sobel_x, padding=1)
        pred_edge_y = F.conv2d(pred_prob, sobel_y, padding=1)
        pred_edge = torch.sqrt(pred_edge_x ** 2 + pred_edge_y ** 2 + 1e-8)

        # çœŸå®è¾¹ç•Œ
        target_float = target.unsqueeze(1).float()
        target_edge_x = F.conv2d(target_float, sobel_x, padding=1)
        target_edge_y = F.conv2d(target_float, sobel_y, padding=1)
        target_edge = torch.sqrt(target_edge_x ** 2 + target_edge_y ** 2 + 1e-8)

        # MSEæŸå¤±
        return F.mse_loss(pred_edge, target_edge)

# ==================== 6. æ•°æ®é›†ç±» ====================
class MultiModalDataset(Dataset):
    """å¤šæ¨¡æ€æ•°æ®é›†"""
    def __init__(self, data_root, split='train', augment=False):
        self.data_root = Path(data_root)
        self.split = split
        self.augment = augment

        self.ct_img_dir = self.data_root / split / 'ct' / 'images'
        self.ct_mask_dir = self.data_root / split / 'ct' / 'masks'
        self.mri_img_dir = self.data_root / split / 'mri' / 'images'
        self.mri_mask_dir = self.data_root / split / 'mri' / 'masks'

        self.ct_files = sorted(self.ct_img_dir.glob('*.png'))

        if len(self.ct_files) == 0:
            raise ValueError(f"æœªæ‰¾åˆ°CTå›¾åƒ: {self.ct_img_dir}")

        print(f"    {split:8s}: {len(self.ct_files)} ä¸ªæ ·æœ¬")

    def __len__(self):
        return len(self.ct_files)

    def __getitem__(self, idx):
        ct_img_path = self.ct_files[idx]
        ct_img = np.array(Image.open(ct_img_path), dtype=np.float32) / 255.0
        ct_mask = np.array(Image.open(self.ct_mask_dir / ct_img_path.name), dtype=np.int64)

        mri_img_path = self.mri_img_dir / ct_img_path.name
        mri_mask_path = self.mri_mask_dir / ct_img_path.name

        if mri_img_path.exists():
            mri_img = np.array(Image.open(mri_img_path), dtype=np.float32) / 255.0
            mri_mask = np.array(Image.open(mri_mask_path), dtype=np.int64)
        else:
            mri_img = np.zeros_like(ct_img, dtype=np.float32)
            mri_mask = np.zeros_like(ct_mask, dtype=np.int64)

        if self.augment:
            ct_img, ct_mask, mri_img, mri_mask = self.apply_augmentation(
                ct_img, ct_mask, mri_img, mri_mask
            )

        ct_img = torch.from_numpy(np.ascontiguousarray(ct_img[None, :, :])).float()
        mri_img = torch.from_numpy(np.ascontiguousarray(mri_img[None, :, :])).float()
        ct_mask = torch.from_numpy(np.ascontiguousarray(ct_mask)).long()
        mri_mask = torch.from_numpy(np.ascontiguousarray(mri_mask)).long()

        return {
            'ct_image': ct_img,
            'mri_image': mri_img,
            'ct_mask': ct_mask,
            'mri_mask': mri_mask
        }

    def apply_augmentation(self, ct_img, ct_mask, mri_img, mri_mask):
        """
        æ•°æ®å¢å¼ºï¼ˆä¿®å¤ç‰ˆï¼‰

        Args:
            ct_img: CTå›¾åƒ [H, W]
            ct_mask: CTæ©ç  [H, W]
            mri_img: MRIå›¾åƒ [H, W]
            mri_mask: MRIæ©ç  [H, W]
        """
        # 1. æ°´å¹³ç¿»è½¬
        if random.random() > 0.5:
            ct_img = np.fliplr(ct_img)
            ct_mask = np.fliplr(ct_mask)
            mri_img = np.fliplr(mri_img)
            mri_mask = np.fliplr(mri_mask)

        # 2. æ—‹è½¬
        if random.random() > 0.5:
            k = random.randint(1, 3)
            ct_img = np.rot90(ct_img, k)
            ct_mask = np.rot90(ct_mask, k)
            mri_img = np.rot90(mri_img, k)
            mri_mask = np.rot90(mri_mask, k)

        # 3. äº®åº¦è°ƒæ•´
        if random.random() > 0.5:
            factor = random.uniform(0.85, 1.15)
            ct_img = np.clip(ct_img * factor, 0, 1)
            mri_img = np.clip(mri_img * factor, 0, 1)

        # 4. é«˜æ–¯å™ªå£°
        if random.random() > 0.5:
            noise_std = random.uniform(0.01, 0.03)
            ct_noise = np.random.randn(*ct_img.shape) * noise_std
            mri_noise = np.random.randn(*mri_img.shape) * noise_std
            ct_img = np.clip(ct_img + ct_noise, 0, 1)
            mri_img = np.clip(mri_img + mri_noise, 0, 1)

        # 5. å¯¹æ¯”åº¦è°ƒæ•´ï¼ˆå¯é€‰ï¼‰
        if random.random() > 0.7:
            # Gammaå˜æ¢
            gamma = random.uniform(0.8, 1.2)
            ct_img = np.power(ct_img, gamma)
            mri_img = np.power(mri_img, gamma)

        return ct_img, ct_mask, mri_img, mri_mask


# ==================== 7. è¯„ä¼°æŒ‡æ ‡ ====================
def calculate_metrics(pred, target, n_classes):
    pred = pred.cpu().numpy()
    target = target.cpu().numpy()

    metrics = {'dice': [], 'iou': [], 'precision': [], 'recall': []}

    for class_id in range(1, n_classes):
        pred_mask = (pred == class_id).astype(np.float32)
        true_mask = (target == class_id).astype(np.float32)

        tp = (pred_mask * true_mask).sum()
        fp = (pred_mask * (1 - true_mask)).sum()
        fn = ((1 - pred_mask) * true_mask).sum()

        dice = (2 * tp) / (2 * tp + fp + fn + 1e-8)
        metrics['dice'].append(dice)

        iou = tp / (tp + fp + fn + 1e-8)
        metrics['iou'].append(iou)

        precision = tp / (tp + fp + 1e-8)
        metrics['precision'].append(precision)

        recall = tp / (tp + fn + 1e-8)
        metrics['recall'].append(recall)

    return {k: np.mean(v) if v else 0.0 for k, v in metrics.items()}


# ==================== TTAå·¥å…·å‡½æ•° ====================

@torch.no_grad()
def predict_with_tta(model, ct_img, mri_img, device, tta_mode='full'):
    """
    æµ‹è¯•æ—¶å¢å¼ºé¢„æµ‹

    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡å‹
        ct_img: CTå›¾åƒ [B, 1, H, W]
        mri_img: MRIå›¾åƒ [B, 1, H, W]
        device: è®¾å¤‡
        tta_mode: å¢å¼ºæ¨¡å¼
            - 'none': ä¸ä½¿ç”¨TTA
            - 'basic': åŸºç¡€TTAï¼ˆç¿»è½¬ï¼Œ2å€é€Ÿåº¦ï¼‰
            - 'full': å®Œæ•´TTAï¼ˆç¿»è½¬+æ—‹è½¬ï¼Œ4å€é€Ÿåº¦ï¼‰

    Returns:
        pred: å¹³å‡åçš„é¢„æµ‹ [B, n_classes, H, W]
    """
    model.eval()
    predictions = []

    if tta_mode == 'none':
        # ä¸ä½¿ç”¨TTAï¼Œç›´æ¥é¢„æµ‹
        pred = model(ct_img, mri_img, return_details=False)
        return pred

    # 1. åŸå§‹å›¾åƒ
    pred = model(ct_img, mri_img, return_details=False)
    predictions.append(pred)

    # 2. æ°´å¹³ç¿»è½¬
    ct_flip_h = torch.flip(ct_img, dims=[-1])
    mri_flip_h = torch.flip(mri_img, dims=[-1])
    pred_flip_h = model(ct_flip_h, mri_flip_h, return_details=False)
    pred_flip_h = torch.flip(pred_flip_h, dims=[-1])  # ç¿»è½¬å›æ¥
    predictions.append(pred_flip_h)

    if tta_mode == 'basic':
        # åŸºç¡€æ¨¡å¼ï¼šåªç”¨ç¿»è½¬
        final_pred = torch.stack(predictions).mean(dim=0)
        return final_pred

    # 3. å‚ç›´ç¿»è½¬
    ct_flip_v = torch.flip(ct_img, dims=[-2])
    mri_flip_v = torch.flip(mri_img, dims=[-2])
    pred_flip_v = model(ct_flip_v, mri_flip_v, return_details=False)
    pred_flip_v = torch.flip(pred_flip_v, dims=[-2])
    predictions.append(pred_flip_v)

    # 4. æ—‹è½¬90åº¦
    ct_rot90 = torch.rot90(ct_img, k=1, dims=[-2, -1])
    mri_rot90 = torch.rot90(mri_img, k=1, dims=[-2, -1])
    pred_rot90 = model(ct_rot90, mri_rot90, return_details=False)
    pred_rot90 = torch.rot90(pred_rot90, k=-1, dims=[-2, -1])  # æ—‹è½¬å›æ¥
    predictions.append(pred_rot90)

    # 5. æ—‹è½¬180åº¦
    ct_rot180 = torch.rot90(ct_img, k=2, dims=[-2, -1])
    mri_rot180 = torch.rot90(mri_img, k=2, dims=[-2, -1])
    pred_rot180 = model(ct_rot180, mri_rot180, return_details=False)
    pred_rot180 = torch.rot90(pred_rot180, k=-2, dims=[-2, -1])
    predictions.append(pred_rot180)

    # 6. æ—‹è½¬270åº¦
    ct_rot270 = torch.rot90(ct_img, k=3, dims=[-2, -1])
    mri_rot270 = torch.rot90(mri_img, k=3, dims=[-2, -1])
    pred_rot270 = model(ct_rot270, mri_rot270, return_details=False)
    pred_rot270 = torch.rot90(pred_rot270, k=-3, dims=[-2, -1])
    predictions.append(pred_rot270)

    # å¹³å‡æ‰€æœ‰é¢„æµ‹
    final_pred = torch.stack(predictions).mean(dim=0)

    return final_pred

# ==================== 8. è®­ç»ƒå™¨ ====================
class CrossDomainTrainer:
    """è·¨åŸŸè®­ç»ƒå™¨"""

    def __init__(self, model, train_loader, val_loader, config, save_dir):  # âœ… æ·»åŠ  save_dir å‚æ•°
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.config = config
        self.device = config['device']
        self.save_dir = Path(save_dir)  # âœ… ç°åœ¨å¯ä»¥æ­£å¸¸ä½¿ç”¨äº†
        self.save_dir.mkdir(parents=True, exist_ok=True)

        # ä¼˜åŒ–å™¨
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=config['lr'],
            weight_decay=config['weight_decay'],
            betas=(0.9, 0.999)
        )

        # ğŸ”¥ å­¦ä¹ ç‡è°ƒåº¦å™¨ - æ›´é•¿warmup
        warmup_scheduler = torch.optim.lr_scheduler.LinearLR(
            self.optimizer,
            start_factor=0.1,
            end_factor=1.0,
            total_iters=config['warmup_epochs']  # 8è½®
        )

        cosine_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=config['epochs'] - config['warmup_epochs'],  # 120-8=112
            eta_min=config['min_lr']  # 5e-7
        )

        self.scheduler = torch.optim.lr_scheduler.SequentialLR(
            self.optimizer,
            schedulers=[warmup_scheduler, cosine_scheduler],
            milestones=[config['warmup_epochs']]
        )

        # ğŸ”¥ è°ƒæ•´åçš„æŸå¤±æƒé‡
        # ğŸ”¥ å¹³è¡¡çš„æŸå¤±æƒé‡ï¼ˆæ–¹æ¡ˆBçš„æŠ˜ä¸­ï¼‰
        self.criterion = MultiModalCrossDomainLoss(
            n_classes=config['n_classes'],
            seg_weight=0.55,  # ğŸ”¥ æŠ˜ä¸­å€¼ï¼ˆ0.5å’Œ0.6ä¹‹é—´ï¼‰
            prior_weight=0.25,  # ğŸ”¥ æŠ˜ä¸­å€¼ï¼ˆ0.2å’Œ0.3ä¹‹é—´ï¼‰
            align_weight=0.20  # ä¿æŒ
        )
        # ğŸ”¥ æ·»åŠ æ ‡ç­¾å¹³æ»‘æŸå¤±ï¼ˆæ–°å¢ï¼‰
        self.smooth_ce = LabelSmoothingCrossEntropy(smoothing=0.05).to(self.device)

        # ğŸ”¥ æ·»åŠ è¾¹ç•ŒæŸå¤±ï¼ˆæ–°å¢ï¼‰
        self.boundary_loss = BoundaryLoss().to(self.device)

        self.use_amp = config.get('use_amp', True)
        if self.use_amp and torch.cuda.is_available():
            self.scaler = torch.cuda.amp.GradScaler()
            print("  âœ… å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ")
        else:
            self.scaler = None

        self.history = {
            'train_loss': [],
            'train_seg_loss': [],
            'train_prior_loss': [],
            'train_align_loss': [],
            'val_loss': [],
            'val_dice': [],
            'val_iou': [],
            'val_precision': [],  # â† æ–°å¢
            'val_recall': [],  # â† æ–°å¢
            'learning_rate': [],
            'epoch_time': []
        }

        self.best_dice = 0.0

    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        epoch_start = time.time()

        total_loss = 0
        total_seg = 0
        total_prior = 0
        total_align = 0
        total_boundary = 0  # ğŸ”¥ æ–°å¢

        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}',
                    bar_format='{l_bar}{bar:30}{r_bar}')
        self.optimizer.zero_grad()

        for i, batch in enumerate(pbar):
            ct_img = batch['ct_image'].to(self.device)
            mri_img = batch['mri_image'].to(self.device)
            ct_mask = batch['ct_mask'].to(self.device)
            mri_mask = batch['mri_mask'].to(self.device)
            ct_prior_gt = batch['ct_prior'].to(self.device)
            mri_prior_gt = batch['mri_prior'].to(self.device)

            if self.use_amp and self.scaler is not None:
                with torch.cuda.amp.autocast():
                    # å‰å‘ä¼ æ’­
                    _, _, _, align_loss = self.model(ct_img, mri_img)

                    ct_pred = self.model.ct_output
                    mri_pred = self.model.mri_output

                    # ğŸ”¥ ä½¿ç”¨æ ‡ç­¾å¹³æ»‘ï¼ˆæ›¿æ¢ F.cross_entropyï¼‰
                    seg_loss_ct = self.smooth_ce(ct_pred, ct_mask)
                    seg_loss_mri = self.smooth_ce(mri_pred, mri_mask)
                    seg_loss = (seg_loss_ct + seg_loss_mri) / 2

                    # PrioræŸå¤±
                    ct_pred_prob = torch.softmax(ct_pred, dim=1)[:, 1:2, :, :]
                    mri_pred_prob = torch.softmax(mri_pred, dim=1)[:, 1:2, :, :]
                    prior_loss = (F.mse_loss(ct_pred_prob, ct_prior_gt) +
                                  F.mse_loss(mri_pred_prob, mri_prior_gt)) / 2

                    # ğŸ”¥ è¾¹ç•ŒæŸå¤±ï¼ˆä½¿ç”¨ self.boundary_lossï¼‰
                    boundary_loss = (self.boundary_loss(ct_pred, ct_mask) +
                                     self.boundary_loss(mri_pred, mri_mask)) / 2

                    # ğŸ”¥ æ€»æŸå¤±ï¼ˆåŠ å…¥è¾¹ç•ŒæŸå¤±ï¼‰
                    loss = (self.criterion.seg_weight * seg_loss +
                            self.criterion.prior_weight * prior_loss +
                            self.criterion.align_weight * align_loss +
                            0.1 * boundary_loss)  # è¾¹ç•ŒæŸå¤±æƒé‡0.1

                    loss = loss / self.config['accumulation_steps']

                # åå‘ä¼ æ’­ + æ¢¯åº¦è£å‰ª
                self.scaler.scale(loss).backward()

                if (i + 1) % self.config['accumulation_steps'] == 0:
                    self.scaler.unscale_(self.optimizer)
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)

                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()

            else:
                # éæ··åˆç²¾åº¦è®­ç»ƒ
                _, _, _, align_loss = self.model(ct_img, mri_img)

                ct_pred = self.model.ct_output
                mri_pred = self.model.mri_output

                # ğŸ”¥ ä½¿ç”¨æ ‡ç­¾å¹³æ»‘
                seg_loss_ct = self.smooth_ce(ct_pred, ct_mask)
                seg_loss_mri = self.smooth_ce(mri_pred, mri_mask)
                seg_loss = (seg_loss_ct + seg_loss_mri) / 2

                # PrioræŸå¤±
                ct_pred_prob = torch.softmax(ct_pred, dim=1)[:, 1:2, :, :]
                mri_pred_prob = torch.softmax(mri_pred, dim=1)[:, 1:2, :, :]
                prior_loss = (F.mse_loss(ct_pred_prob, ct_prior_gt) +
                              F.mse_loss(mri_pred_prob, mri_prior_gt)) / 2

                # ğŸ”¥ è¾¹ç•ŒæŸå¤±
                boundary_loss = (self.boundary_loss(ct_pred, ct_mask) +
                                 self.boundary_loss(mri_pred, mri_mask)) / 2

                # æ€»æŸå¤±
                loss = (self.criterion.seg_weight * seg_loss +
                        self.criterion.prior_weight * prior_loss +
                        self.criterion.align_weight * align_loss +
                        0.1 * boundary_loss)

                loss = loss / self.config['accumulation_steps']
                loss.backward()

                if (i + 1) % self.config['accumulation_steps'] == 0:
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                    self.optimizer.step()
                    self.optimizer.zero_grad()

            # ç´¯è®¡æŸå¤±
            total_loss += loss.item() * self.config['accumulation_steps']
            total_seg += seg_loss.item()
            total_prior += prior_loss.item()
            total_align += align_loss.item()
            total_boundary += boundary_loss.item()  # ğŸ”¥ æ–°å¢

            pbar.set_postfix({
                'loss': f'{loss.item() * self.config["accumulation_steps"]:.4f}',
                'seg': f'{seg_loss.item():.4f}',
                'prior': f'{prior_loss.item():.4f}',
                'align': f'{align_loss.item():.4f}',
                'bound': f'{boundary_loss.item():.4f}'  # ğŸ”¥ æ˜¾ç¤ºè¾¹ç•ŒæŸå¤±
            })

        epoch_time = time.time() - epoch_start

        return {
                   'total': total_loss / len(self.train_loader),
                   'seg': total_seg / len(self.train_loader),
                   'prior': total_prior / len(self.train_loader),
                   'align': total_align / len(self.train_loader),
                   'boundary': total_boundary / len(self.train_loader)  # ğŸ”¥ æ–°å¢
               }, epoch_time

    def _tta_forward(self, ct_img, mri_img, mode='simple'):
        """
        æµ‹è¯•æ—¶å¢å¼º(TTA)å‰å‘ä¼ æ’­

        Returns:
            ct_pred: [B, 2, H, W]
            mri_pred: [B, 2, H, W]
        """
        ct_predictions = []
        mri_predictions = []

        # 1. åŸå›¾
        with torch.no_grad():
            self.model(ct_img, mri_img)
            ct_predictions.append(self.model.ct_output.clone())
            mri_predictions.append(self.model.mri_output.clone())

        if mode == 'full':
            # 2. æ°´å¹³ç¿»è½¬
            ct_flip = torch.flip(ct_img, dims=[-1])
            mri_flip = torch.flip(mri_img, dims=[-1])
            self.model(ct_flip, mri_flip)
            ct_predictions.append(torch.flip(self.model.ct_output, dims=[-1]))
            mri_predictions.append(torch.flip(self.model.mri_output, dims=[-1]))

            # 3. å‚ç›´ç¿»è½¬
            ct_vflip = torch.flip(ct_img, dims=[-2])
            mri_vflip = torch.flip(mri_img, dims=[-2])
            self.model(ct_vflip, mri_vflip)
            ct_predictions.append(torch.flip(self.model.ct_output, dims=[-2]))
            mri_predictions.append(torch.flip(self.model.mri_output, dims=[-2]))

            # 4. æ—‹è½¬90åº¦
            ct_rot90 = torch.rot90(ct_img, k=1, dims=[-2, -1])
            mri_rot90 = torch.rot90(mri_img, k=1, dims=[-2, -1])
            self.model(ct_rot90, mri_rot90)
            ct_predictions.append(torch.rot90(self.model.ct_output, k=-1, dims=[-2, -1]))
            mri_predictions.append(torch.rot90(self.model.mri_output, k=-1, dims=[-2, -1]))

        # å¹³å‡æ‰€æœ‰é¢„æµ‹
        ct_final = torch.stack(ct_predictions).mean(dim=0)  # [B, 2, H, W]
        mri_final = torch.stack(mri_predictions).mean(dim=0)

        return ct_final, mri_final

    @torch.no_grad()
    def validate(self, use_tta=False, tta_mode='simple'):
        """éªŒè¯å‡½æ•° - å®Œå…¨ä¿®å¤ç‰ˆ"""
        self.model.eval()

        total_loss = 0.0

        # CTå’ŒMRIåˆ†åˆ«ç»Ÿè®¡
        ct_intersection = 0
        ct_union = 0
        ct_pred_sum = 0
        ct_gt_sum = 0
        ct_tp = 0
        ct_fp = 0
        ct_fn = 0

        mri_intersection = 0
        mri_union = 0
        mri_pred_sum = 0
        mri_gt_sum = 0
        mri_tp = 0
        mri_fp = 0
        mri_fn = 0

        pbar = tqdm(self.val_loader, desc='ğŸ” Validating', leave=False,
                    bar_format='{l_bar}{bar:30}{r_bar}')

        for batch in pbar:
            ct_img = batch['ct_image'].to(self.device)
            mri_img = batch['mri_image'].to(self.device)
            ct_mask = batch['ct_mask'].to(self.device)
            mri_mask = batch['mri_mask'].to(self.device)
            ct_prior_gt = batch['ct_prior'].to(self.device)
            mri_prior_gt = batch['mri_prior'].to(self.device)

            if use_tta:
                # TTAæ¨¡å¼
                ct_pred_logits, mri_pred_logits = self._tta_forward(ct_img, mri_img, mode=tta_mode)
                loss = torch.tensor(0.0).to(self.device)
            else:
                # æ­£å¸¸éªŒè¯
                _, _, _, align_loss = self.model(ct_img, mri_img)

                # è·å–é¢„æµ‹
                ct_pred_logits = self.model.ct_output
                mri_pred_logits = self.model.mri_output

                # è®¡ç®—æŸå¤±
                seg_loss_ct = F.cross_entropy(ct_pred_logits, ct_mask)
                seg_loss_mri = F.cross_entropy(mri_pred_logits, mri_mask)
                seg_loss = (seg_loss_ct + seg_loss_mri) / 2

                # PrioræŸå¤±
                ct_pred_prob = torch.softmax(ct_pred_logits, dim=1)[:, 1:2, :, :]
                mri_pred_prob = torch.softmax(mri_pred_logits, dim=1)[:, 1:2, :, :]
                prior_loss = (F.mse_loss(ct_pred_prob, ct_prior_gt) +
                              F.mse_loss(mri_pred_prob, mri_prior_gt)) / 2

                loss = (self.criterion.seg_weight * seg_loss +
                        self.criterion.prior_weight * prior_loss +
                        self.criterion.align_weight * align_loss)

                total_loss += loss.item()

            # ğŸ”¥ è·å–é¢„æµ‹ç±»åˆ«ï¼ˆç¡®ä¿æ˜¯Tensorï¼‰
            pred_ct = ct_pred_logits.argmax(dim=1)  # [B, H, W] - Tensor
            pred_mri = mri_pred_logits.argmax(dim=1)

            # ğŸ”¥ è½¬ä¸ºäºŒå€¼Tensorï¼ˆä¸è¦è½¬NumPyï¼‰
            pred_ct_binary = (pred_ct == 1).float()  # Tensor
            mask_ct_binary = (ct_mask == 1).float()

            # å±•å¹³
            pred_ct_binary = pred_ct_binary.reshape(-1)
            mask_ct_binary = mask_ct_binary.reshape(-1)

            # ç´¯åŠ æŒ‡æ ‡
            ct_intersection += (pred_ct_binary * mask_ct_binary).sum().item()
            ct_union += ((pred_ct_binary + mask_ct_binary) > 0).float().sum().item()
            ct_pred_sum += pred_ct_binary.sum().item()
            ct_gt_sum += mask_ct_binary.sum().item()

            ct_tp += ((pred_ct_binary == 1) & (mask_ct_binary == 1)).float().sum().item()
            ct_fp += ((pred_ct_binary == 1) & (mask_ct_binary == 0)).float().sum().item()
            ct_fn += ((pred_ct_binary == 0) & (mask_ct_binary == 1)).float().sum().item()

            # ğŸ”¥ MRIæŒ‡æ ‡
            pred_mri_binary = (pred_mri == 1).float()
            mask_mri_binary = (mri_mask == 1).float()

            pred_mri_binary = pred_mri_binary.reshape(-1)
            mask_mri_binary = mask_mri_binary.reshape(-1)

            mri_intersection += (pred_mri_binary * mask_mri_binary).sum().item()
            mri_union += ((pred_mri_binary + mask_mri_binary) > 0).float().sum().item()
            mri_pred_sum += pred_mri_binary.sum().item()
            mri_gt_sum += mask_mri_binary.sum().item()

            mri_tp += ((pred_mri_binary == 1) & (mask_mri_binary == 1)).float().sum().item()
            mri_fp += ((pred_mri_binary == 1) & (mask_mri_binary == 0)).float().sum().item()
            mri_fn += ((pred_mri_binary == 0) & (mask_mri_binary == 1)).float().sum().item()

        # è®¡ç®—å¹³å‡æŒ‡æ ‡
        dice_ct = (2 * ct_intersection + 1e-8) / (ct_pred_sum + ct_gt_sum + 1e-8)
        dice_mri = (2 * mri_intersection + 1e-8) / (mri_pred_sum + mri_gt_sum + 1e-8)
        dice = (dice_ct + dice_mri) / 2

        iou_ct = (ct_intersection + 1e-8) / (ct_union + 1e-8)
        iou_mri = (mri_intersection + 1e-8) / (mri_union + 1e-8)
        iou = (iou_ct + iou_mri) / 2

        precision_ct = (ct_tp + 1e-8) / (ct_tp + ct_fp + 1e-8)
        precision_mri = (mri_tp + 1e-8) / (mri_tp + mri_fp + 1e-8)
        precision = (precision_ct + precision_mri) / 2

        recall_ct = (ct_tp + 1e-8) / (ct_tp + ct_fn + 1e-8)
        recall_mri = (mri_tp + 1e-8) / (mri_tp + mri_fn + 1e-8)
        recall = (recall_ct + recall_mri) / 2

        avg_loss = total_loss / len(self.val_loader) if not use_tta else 0.0

        return {
            'loss': avg_loss,
            'dice': dice,
            'dice_ct': dice_ct,
            'dice_mri': dice_mri,
            'iou': iou,
            'precision': precision,
            'recall': recall
        }




    def save_checkpoint(self, epoch, metrics, losses, is_best=False):
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'metrics': metrics,
            'losses': losses,
            'history': self.history,
            'config': self.config,
            'best_dice': self.best_dice
        }

        checkpoint_path = self.config['checkpoint_dir'] / 'latest.pth'
        torch.save(checkpoint, checkpoint_path)

        if is_best:
            best_path = self.config['checkpoint_dir'] / 'best.pth'
            torch.save(checkpoint, best_path)
            print(f"        âœ… ä¿å­˜æœ€ä½³æ¨¡å‹! Dice={metrics['dice']:.4f}")

    def train(self):
        """è®­ç»ƒä¸»å¾ªç¯"""
        patience_counter = 0

        for epoch in range(1, self.config['epochs'] + 1):
            # ğŸ”¥ Warmupå­¦ä¹ ç‡è°ƒæ•´ï¼ˆåœ¨è®­ç»ƒepochä¹‹å‰ï¼‰
            if epoch <= self.config.get('warmup_epochs', 10):
                lr = self.config['lr'] * (epoch / self.config['warmup_epochs'])
                for param_group in self.optimizer.param_groups:
                    param_group['lr'] = lr

            # è®­ç»ƒä¸€ä¸ªepoch
            train_losses, epoch_time = self.train_epoch(epoch)

            # ğŸ”¥ è·å–å½“å‰å­¦ä¹ ç‡ï¼ˆåœ¨è°ƒåº¦å™¨è°ƒæ•´ä¹‹å‰ï¼‰
            current_lr = self.optimizer.param_groups[0]['lr']

            # éªŒè¯
            if epoch == 1 or epoch % 10 == 0:
                print(f"\n        ğŸ” ä½¿ç”¨TTAéªŒè¯...")
                val_metrics = self.validate(use_tta=True, tta_mode='full')
            else:
                val_metrics = self.validate(use_tta=False)

            # ğŸ”¥ å­¦ä¹ ç‡è°ƒåº¦ï¼ˆåœ¨è·å–current_lrä¹‹åï¼‰
            if self.scheduler is not None:
                if isinstance(self.scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
                    self.scheduler.step(val_metrics['dice'])
                else:
                    self.scheduler.step()

            # è®°å½•å†å²
            self.history['train_loss'].append(train_losses['total'])
            self.history['train_seg_loss'].append(train_losses['seg'])
            self.history['train_prior_loss'].append(train_losses['prior'])
            self.history['train_align_loss'].append(train_losses['align'])

            # ğŸ”¥ è¾¹ç•ŒæŸå¤±ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            if 'boundary' in train_losses:
                if 'train_boundary_loss' not in self.history:
                    self.history['train_boundary_loss'] = []
                self.history['train_boundary_loss'].append(train_losses['boundary'])

            self.history['val_loss'].append(val_metrics['loss'])
            self.history['val_dice'].append(val_metrics['dice'])
            self.history['val_iou'].append(val_metrics['iou'])
            self.history['val_precision'].append(val_metrics.get('precision', 0.0))
            self.history['val_recall'].append(val_metrics.get('recall', 0.0))
            self.history['learning_rate'].append(current_lr)
            self.history['epoch_time'].append(epoch_time)

            # æ‰“å°ç»“æœ
            print(f"\n    Epoch {epoch}/{self.config['epochs']} ({epoch_time:.1f}s):")
            print(f"        Train Loss: {train_losses['total']:.4f} "
                  f"(Seg:{train_losses['seg']:.4f}, "
                  f"Prior:{train_losses['prior']:.4f}, "
                  f"Align:{train_losses['align']:.4f})")
            print(f"        Val Loss:   {val_metrics['loss']:.4f}")
            print(f"        Val Dice:   {val_metrics['dice']:.4f} {'ğŸ”¥' if val_metrics['dice'] > 0.85 else ''}")
            print(f"        Val IoU:    {val_metrics['iou']:.4f}")
            print(f"        Precision:  {val_metrics.get('precision', 0.0):.4f}")
            print(f"        Recall:     {val_metrics.get('recall', 0.0):.4f}")
            print(f"        LR:         {current_lr:.6f}")  # âœ… ç°åœ¨å¯ä»¥æ­£å¸¸ä½¿ç”¨äº†

            # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
            current_dice = val_metrics['dice']
            is_best = current_dice > self.best_dice

            if is_best:
                improvement = current_dice - self.best_dice
                self.best_dice = current_dice
                patience_counter = 0
                print(f"        âœ… æ–°çš„æœ€ä½³Dice: {current_dice:.4f} (â†‘{improvement:.4f})")
            else:
                patience_counter += 1
                print(
                    f"        â¸ï¸  æœªæå‡ (æœ€ä½³: {self.best_dice:.4f}), patience: {patience_counter}/{self.config['patience']}")

            # ä¿å­˜æ£€æŸ¥ç‚¹
            self.save_checkpoint(epoch, val_metrics, train_losses, is_best)

            # æ—©åœåˆ¤æ–­
            if patience_counter >= self.config['patience']:
                print(f"\nâ¹ï¸  æ—©åœè§¦å‘! {self.config['patience']}è½®æœªæå‡")
                break

        print(f"\nğŸ‰ è®­ç»ƒå®Œæˆ! æœ€ä½³Dice: {self.best_dice:.4f}")

        # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
        self.plot_history()

    def plot_history(self):
        try:
            fig, axes = plt.subplots(3, 3, figsize=(20, 15))

            # æ€»æŸå¤±
            axes[0, 0].plot(self.history['train_loss'], label='Train', linewidth=2)
            axes[0, 0].plot(self.history['val_loss'], label='Val', linewidth=2)
            axes[0, 0].set_title('Total Loss', fontweight='bold')
            axes[0, 0].legend()
            axes[0, 0].grid(alpha=0.3)

            # åˆ†å‰²æŸå¤±
            axes[0, 1].plot(self.history['train_seg_loss'], label='Seg Loss', linewidth=2)
            axes[0, 1].set_title('Segmentation Loss', fontweight='bold')
            axes[0, 1].legend()
            axes[0, 1].grid(alpha=0.3)

            # å…ˆéªŒæŸå¤±
            axes[0, 2].plot(self.history['train_prior_loss'], label='Prior Loss',
                            color='orange', linewidth=2)
            axes[0, 2].set_title('Prior Mask Loss', fontweight='bold')
            axes[0, 2].legend()
            axes[0, 2].grid(alpha=0.3)

            # å¯¹é½æŸå¤±
            axes[1, 0].plot(self.history['train_align_loss'], label='Align Loss',
                            color='red', linewidth=2)
            axes[1, 0].set_title('Domain Alignment Loss', fontweight='bold')
            axes[1, 0].legend()
            axes[1, 0].grid(alpha=0.3)

            # Dice
            axes[1, 1].plot(self.history['val_dice'], label='Val Dice',
                            color='green', linewidth=2)
            axes[1, 1].axhline(self.best_dice, color='r', linestyle='--',
                               label=f'Best: {self.best_dice:.4f}')
            axes[1, 1].set_title('Validation Dice', fontweight='bold')
            axes[1, 1].legend()
            axes[1, 1].grid(alpha=0.3)

            # IoU
            axes[1, 2].plot(self.history['val_iou'], label='Val IoU',
                            color='purple', linewidth=2)
            axes[1, 2].set_title('Validation IoU', fontweight='bold')
            axes[1, 2].legend()
            axes[1, 2].grid(alpha=0.3)

            # å­¦ä¹ ç‡
            axes[2, 0].plot(self.history['learning_rate'], color='brown', linewidth=2)
            axes[2, 0].set_title('Learning Rate', fontweight='bold')
            axes[2, 0].set_yscale('log')
            axes[2, 0].grid(alpha=0.3)

            # æ—¶é—´
            axes[2, 1].plot(self.history['epoch_time'], color='navy', linewidth=2)
            axes[2, 1].axhline(np.mean(self.history['epoch_time']), color='r',
                               linestyle='--', label=f'Avg: {np.mean(self.history["epoch_time"]):.1f}s')
            axes[2, 1].set_title('Training Time', fontweight='bold')
            axes[2, 1].legend()
            axes[2, 1].grid(alpha=0.3)

            # Dice vs IoU
            axes[2, 2].plot(self.history['val_dice'], label='Dice', linewidth=2)
            axes[2, 2].plot(self.history['val_iou'], label='IoU', linewidth=2)
            axes[2, 2].set_title('Dice vs IoU', fontweight='bold')
            axes[2, 2].legend()
            axes[2, 2].grid(alpha=0.3)

            plt.tight_layout()
            save_path = self.config['checkpoint_dir'] / 'training_history.png'
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"\nâœ… è®­ç»ƒæ›²çº¿å·²ä¿å­˜: {save_path}")
            plt.show()

        except Exception as e:
            print(f"âš ï¸ ç»˜åˆ¶å¤±è´¥: {e}")


# ==================== 9. ä¸»è®­ç»ƒå‡½æ•° ====================
def train_cross_domain():
    """ä¸»è®­ç»ƒå‡½æ•°"""

    print("\n" + "=" * 80)
    print("ğŸš€ å¤šæ¨¡æ€è·¨åŸŸè‡ªé€‚åº”UNetè®­ç»ƒ")
    print("=" * 80)

    config = {
        'data_root': r'D:\AåŸºäºUNetå®ç°å¤šæ¨¡æ€è·¨åŸŸè‡ªé€‚åº”\unet\Pytorch-UNet-master\data\mmwhs_processed',
        'n_classes': 2,
        'bilinear': True,
        'base_channels': 32,

        # è®­ç»ƒå‚æ•°
        'epochs': 150,  # ğŸ”¥ å¢åŠ åˆ°150
        'batch_size': 8,
        'lr': 7e-4,  # ğŸ”¥ ç•¥å¾®é™ä½
        'weight_decay': 6e-4,  # ğŸ”¥ å¢åŠ æ­£åˆ™åŒ–
        'accumulation_steps': 1,
        'use_amp': True,

        # å­¦ä¹ ç‡è°ƒåº¦
        'warmup_epochs': 10,  # ğŸ”¥ å¢åŠ warmup
        'min_lr': 3e-7,  # ğŸ”¥ é™ä½æœ€å°å­¦ä¹ ç‡

        # æ—©åœ
        'patience': 25,  # ğŸ”¥ å¢åŠ patience
        'min_delta': 5e-5,

        # æ•°æ®åŠ è½½
        'num_workers': 6,
        'pin_memory': True,
        'prefetch_factor': 3,

        'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),
        'checkpoint_dir': Path('checkpoints_mmwhs_optimized') / datetime.now().strftime('%Y%m%d_%H%M%S')
    }

    config['checkpoint_dir'].mkdir(parents=True, exist_ok=True)

    print("=" * 80)
    print("ğŸš€ å¤šæ¨¡æ€è·¨åŸŸè‡ªé€‚åº”UNetè®­ç»ƒ")
    print("=" * 80)
    print(f"\nã€é…ç½®ä¿¡æ¯ã€‘")
    print(f"  æ•°æ®è·¯å¾„: {config['data_root']}")
    print(f"  è®¾å¤‡: {config['device']}")

    if torch.cuda.is_available():
        print(f"  GPU: {torch.cuda.get_device_name(0)}")
        print(f"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")

    print(f"\nã€è®­ç»ƒé…ç½®ã€‘")
    print(f"  Epochs: {config['epochs']}")
    print(f"  Batch Size: {config['batch_size']}")
    print(f"  Learning Rate: {config['lr']}")
    print(f"  Warmup Epochs: {config['warmup_epochs']}")
    print(f"  Patience: {config['patience']}")

    # åŠ è½½æ•°æ®
    try:
        from mmwhs_dataset import create_mmwhs_loaders
        train_loader, val_loader = create_mmwhs_loaders(
            data_root=config['data_root'],
            batch_size=config['batch_size'],
            num_workers=config['num_workers'],
            pin_memory=config['pin_memory'],
            prefetch_factor=config['prefetch_factor']
        )
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # åˆ›å»ºæ¨¡å‹
    # åˆ›å»ºæ¨¡å‹
    try:
        # âœ… ç›´æ¥ä½¿ç”¨æœ¬æ–‡ä»¶ä¸­å®šä¹‰çš„ç±»
        model = MultiModalCrossDomainUNet(  # â† æ”¹è¿™é‡Œ
            n_classes=config['n_classes'],
            bilinear=config['bilinear'],
            base_channels=config['base_channels']
        ).to(config['device'])

        n_params = sum(p.numel() for p in model.parameters()) / 1e6
        print(f"\n  ã€æ¨¡å‹ä¿¡æ¯ã€‘")
        print(f"  å‚æ•°é‡: {n_params:.2f}M")

    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # å¼€å§‹è®­ç»ƒ
    try:
        save_dir = config['checkpoint_dir']
        save_dir.mkdir(parents=True, exist_ok=True)

        trainer = CrossDomainTrainer(
            model=model,
            train_loader=train_loader,
            val_loader=val_loader,
            config=config,
            save_dir=save_dir  # ğŸ”¥ ç¡®ä¿ä¼ å…¥
        )
        trainer.train()

    except RuntimeError as e:
        if "out of memory" in str(e):
            print("\nâŒ GPUæ˜¾å­˜ä¸è¶³!")
            print("å»ºè®®:")
            print("  1. batch_size æ”¹ä¸º 4")
            print("  2. base_channels æ”¹ä¸º 24")
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        else:
            import traceback
            traceback.print_exc()

    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

    # ğŸ”¥ åˆ é™¤è¿™é‡Œçš„æ‰€æœ‰é¢å¤–è°ƒç”¨
    # train_cross_domain()  â† åˆ é™¤è¿™ä¸€è¡Œ!!!

    print("\nâœ… train_cross_domain() å‡½æ•°æ‰§è¡Œå®Œæ¯•\n")


# ==================== 10. ç¨‹åºå…¥å£ ====================

if __name__ == '__main__':
    import sys

    # é˜²æ­¢é‡å¤è¿è¡Œæ£€æŸ¥
    print("\n" + "ğŸ””" * 40)
    print("ğŸ“Œ è„šæœ¬å¯åŠ¨æ£€æŸ¥")
    print(f"   å½“å‰è„šæœ¬: {sys.argv[0]}")
    print(f"   Pythonç‰ˆæœ¬: {sys.version}")
    print("ğŸ””" * 40 + "\n")

    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    torch.cuda.manual_seed_all(42)
    np.random.seed(42)
    random.seed(42)

    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(message)s'
    )

    print("\n" + "=" * 80)
    print("ğŸ¯ å¤šæ¨¡æ€è·¨åŸŸè‡ªé€‚åº”UNet")
    print("=" * 80)
    print("\nã€æ ¸å¿ƒåˆ›æ–°ã€‘")
    print("  1. è¯­ä¹‰ç›¸ä¼¼åº¦è‡ªé€‚åº”èåˆ")
    print("     - CTå’ŒMRIç‰¹å¾åŠ¨æ€æƒé‡åˆ†é…")
    print("     - è§£å†³ç‰¹å¾é”™ä½å’Œè¯­ä¹‰ä¸ä¸€è‡´")
    print("\n  2. åŠ¨æ€å¤šæ¨¡æ€å…ˆéªŒæ©ç å¼•å¯¼")
    print("     - CTç»“æ„å…ˆéªŒ + MRIç»†èŠ‚å…ˆéªŒ")
    print("     - ç²—åˆ°ç²¾çš„åˆ†å‰²å¼•å¯¼")
    print("\n  3. è·¨åŸŸè‡ªé€‚åº”å¯¹é½")
    print("     - å¯¹æŠ—è®­ç»ƒå®ç°åŸŸä¸å˜ç‰¹å¾")
    print("     - CT(æºåŸŸ) â†” MRI(ç›®æ ‡åŸŸ)å¯¹é½")
    print("\n  4. ç½®ä¿¡åº¦å¼•å¯¼çš„èåˆ")
    print("     - è¯„ä¼°å…ˆéªŒå¯é æ€§")
    print("     - è‡ªé€‚åº”è°ƒæ•´èåˆç­–ç•¥")
    print("\n" + "=" * 80)

    # ğŸ”¥ åªè°ƒç”¨ä¸€æ¬¡è®­ç»ƒå‡½æ•°
    try:
        train_cross_domain()
        print("\nâœ… è®­ç»ƒæµç¨‹æ­£å¸¸ç»“æŸ")

    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()

    finally:
        print("\n" + "=" * 80)
        print("âœ… è®­ç»ƒè„šæœ¬æ‰§è¡Œå®Œæˆ!")
        print("=" * 80)

        # ğŸ”¥ å¼ºåˆ¶é€€å‡ºï¼Œé˜²æ­¢ä»»ä½•å¯èƒ½çš„é‡å¤
        print("\nğŸ›‘ å³å°†é€€å‡º...")
        sys.exit(0)