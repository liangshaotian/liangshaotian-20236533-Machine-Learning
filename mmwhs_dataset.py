"""
MMWHSæ•°æ®é›†åŠ è½½å™¨
é€‚é…train_cross_domain.pyçš„å¤šæ¨¡æ€è®­ç»ƒ
"""

import torch
from torch.utils.data import Dataset, DataLoader
from pathlib import Path
from PIL import Image
import numpy as np
import random
from scipy.ndimage import zoom

class MMWHSDataset(Dataset):
    """MMWHSé…å¯¹CT-MRæ•°æ®é›†"""

    def __init__(self, data_root, split='train', augment=False):
        """
        Args:
            data_root: å¤„ç†åçš„æ•°æ®æ ¹ç›®å½•
            split: 'train' æˆ– 'val'
            augment: æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼º
        """
        self.data_root = Path(data_root)
        self.split = split
        self.augment = augment

        # æ•°æ®è·¯å¾„ï¼ˆåªä½¿ç”¨è®­ç»ƒé›†ï¼Œå› ä¸ºæµ‹è¯•é›†æ²¡æœ‰æ ‡æ³¨ï¼‰
        self.ct_img_dir = self.data_root / 'train' / 'ct' / 'images'
        self.ct_mask_dir = self.data_root / 'train' / 'ct' / 'masks'
        self.mr_img_dir = self.data_root / 'train' / 'mr' / 'images'
        self.mr_mask_dir = self.data_root / 'train' / 'mr' / 'masks'

        # è·å–æ–‡ä»¶åˆ—è¡¨
        self.ct_files = sorted(self.ct_img_dir.glob('*.png'))
        self.mr_files = sorted(self.mr_img_dir.glob('*.png'))

        # ç¡®ä¿æ•°æ®å­˜åœ¨
        if len(self.ct_files) == 0 or len(self.mr_files) == 0:
            raise ValueError(f"æ•°æ®é›†ä¸ºç©ºï¼CT: {len(self.ct_files)}, MR: {len(self.mr_files)}")

        # å–è¾ƒå°‘çš„ä¸€æ–¹ä½œä¸ºé…å¯¹æ•°é‡
        self.num_samples = min(len(self.ct_files), len(self.mr_files))

        # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆ80/20ï¼‰
        if split == 'train':
            self.indices = list(range(0, int(0.8 * self.num_samples)))
        else:  # val
            self.indices = list(range(int(0.8 * self.num_samples), self.num_samples))

        print(f"MMWHS {split}é›†: {len(self.indices)} ä¸ªé…å¯¹æ ·æœ¬")

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        """è¿”å›æ ¼å¼ï¼š{'ct_image': ..., 'ct_mask': ..., 'mri_image': ..., 'mri_mask': ...,
                      'ct_prior': ..., 'mri_prior': ...}"""
        real_idx = self.indices[idx]

        # åŠ è½½CT
        ct_img_path = self.ct_files[real_idx]
        ct_mask_path = self.ct_mask_dir / ct_img_path.name
        ct_img = Image.open(ct_img_path).convert('L')
        ct_mask = Image.open(ct_mask_path).convert('L')

        # åŠ è½½MR
        mr_img_path = self.mr_files[real_idx]
        mr_mask_path = self.mr_mask_dir / mr_img_path.name
        mr_img = Image.open(mr_img_path).convert('L')
        mr_mask = Image.open(mr_mask_path).convert('L')

        # è½¬numpy
        ct_img = np.array(ct_img, dtype=np.float32) / 255.0
        mr_img = np.array(mr_img, dtype=np.float32) / 255.0
        ct_mask = np.array(ct_mask, dtype=np.float32) / 255.0
        mr_mask = np.array(mr_mask, dtype=np.float32) / 255.0

        # ğŸ”¥ ç”Ÿæˆå¼±å…ˆéªŒï¼ˆä»å›¾åƒç”Ÿæˆï¼Œä¸æ˜¯ä»maskï¼‰
        ct_prior = self._generate_weak_prior(ct_img)
        mri_prior = self._generate_weak_prior(mr_img)

        # æ•°æ®å¢å¼º
        if self.augment:
            ct_img, ct_mask, mr_img, mr_mask, ct_prior, mri_prior = self._augment(
                ct_img, ct_mask, mr_img, mr_mask, ct_prior, mri_prior
            )

        # è½¬tensor
        ct_img = torch.from_numpy(ct_img.astype(np.float32)).unsqueeze(0)
        mr_img = torch.from_numpy(mr_img.astype(np.float32)).unsqueeze(0)

        ct_prior = torch.from_numpy(ct_prior.astype(np.float32)).unsqueeze(0)
        mri_prior = torch.from_numpy(mri_prior.astype(np.float32)).unsqueeze(0)

        # maskäºŒå€¼åŒ–
        ct_mask = (ct_mask > 0.5).astype(np.int64)
        mr_mask = (mr_mask > 0.5).astype(np.int64)
        ct_mask = torch.from_numpy(ct_mask).long()
        mr_mask = torch.from_numpy(mr_mask).long()

        return {
            'ct_image': ct_img,
            'ct_mask': ct_mask,
            'mri_image': mr_img,
            'mri_mask': mr_mask,
            'ct_prior': ct_prior,  # ğŸ”¥ æ–°å¢
            'mri_prior': mri_prior  # ğŸ”¥ æ–°å¢
        }

    def _generate_weak_prior(self, img):
        """å¤šå°ºåº¦å…ˆéªŒèåˆï¼ˆæ”¹è¿›ç‰ˆï¼‰"""
        from scipy.ndimage import gaussian_filter, binary_opening, binary_closing
        from skimage.filters import threshold_otsu, threshold_li

        priors = []

        # ğŸ”¥ æ–¹æ³•1: Otsuè‡ªé€‚åº”é˜ˆå€¼
        try:
            t1 = threshold_otsu(img)
            b1 = (img > t1).astype(np.float32)
            # å½¢æ€å­¦æ“ä½œï¼ˆæ›´å¼ºï¼‰
            b1 = binary_opening(b1, iterations=3)
            b1 = binary_closing(b1, iterations=4)
            # é«˜æ–¯å¹³æ»‘
            p1 = gaussian_filter(b1, sigma=6)
            priors.append(p1)
        except:
            pass

        # ğŸ”¥ æ–¹æ³•2: Lié˜ˆå€¼ï¼ˆå¯¹ä½å¯¹æ¯”åº¦å›¾åƒæ›´é²æ£’ï¼‰
        try:
            t2 = threshold_li(img)
            b2 = (img > t2).astype(np.float32)
            b2 = binary_opening(b2, iterations=2)
            b2 = binary_closing(b2, iterations=3)
            p2 = gaussian_filter(b2, sigma=8)
            priors.append(p2)
        except:
            pass

        # ğŸ”¥ æ–¹æ³•3: ç™¾åˆ†ä½æ•°ï¼ˆé²æ£’çš„å¤‡é€‰æ–¹æ¡ˆï¼‰
        t3 = np.percentile(img, 65)  # 65åˆ†ä½æ•°
        b3 = (img > t3).astype(np.float32)
        b3 = binary_opening(b3, iterations=2)
        b3 = binary_closing(b3, iterations=3)
        p3 = gaussian_filter(b3, sigma=7)
        priors.append(p3)

        # ğŸ”¥ èåˆå¤šä¸ªå…ˆéªŒï¼ˆåŠ æƒå¹³å‡ï¼Œä¼˜å…ˆä½¿ç”¨Otsuï¼‰
        if len(priors) == 3:
            # Otsuæƒé‡0.5, Liæƒé‡0.3, ç™¾åˆ†ä½æƒé‡0.2
            prior = 0.5 * priors[0] + 0.3 * priors[1] + 0.2 * priors[2]
        elif len(priors) == 2:
            prior = 0.6 * priors[0] + 0.4 * priors[1]
        else:
            prior = priors[0]

        # å½’ä¸€åŒ–
        if prior.max() > 0:
            prior = prior / prior.max()

        # ğŸ”¥ é˜²æ­¢è¿‡åº¦å¹³æ»‘ï¼ˆä¿ç•™ç»†èŠ‚ï¼‰
        prior = np.clip(prior, 0.0, 1.0)

        return prior

    def _augment(self, ct_img, ct_mask, mri_img, mri_mask, ct_prior, mri_prior):
        """å¢å¼ºçš„æ•°æ®å¢å¼º"""

        # 1. éšæœºæ°´å¹³ç¿»è½¬ï¼ˆ60%æ¦‚ç‡ï¼‰
        if random.random() > 0.4:
            ct_img = np.fliplr(ct_img).copy()
            ct_mask = np.fliplr(ct_mask).copy()
            ct_prior = np.fliplr(ct_prior).copy()
            mri_img = np.fliplr(mri_img).copy()
            mri_mask = np.fliplr(mri_mask).copy()
            mri_prior = np.fliplr(mri_prior).copy()

        # 2. éšæœºå‚ç›´ç¿»è½¬ï¼ˆ60%æ¦‚ç‡ï¼‰
        if random.random() > 0.4:
            ct_img = np.flipud(ct_img).copy()
            ct_mask = np.flipud(ct_mask).copy()
            ct_prior = np.flipud(ct_prior).copy()
            mri_img = np.flipud(mri_img).copy()
            mri_mask = np.flipud(mri_mask).copy()
            mri_prior = np.flipud(mri_prior).copy()

        # 3. éšæœºæ—‹è½¬ï¼ˆ50%æ¦‚ç‡ï¼‰
        if random.random() > 0.5:
            k = random.randint(1, 3)
            ct_img = np.rot90(ct_img, k).copy()
            ct_mask = np.rot90(ct_mask, k).copy()
            ct_prior = np.rot90(ct_prior, k).copy()
            mri_img = np.rot90(mri_img, k).copy()
            mri_mask = np.rot90(mri_mask, k).copy()
            mri_prior = np.rot90(mri_prior, k).copy()

        # ğŸ”¥ 4. å¼¹æ€§å˜å½¢ï¼ˆæ–°å¢ï¼Œ30%æ¦‚ç‡ï¼‰
        if random.random() > 0.7:
            from scipy.ndimage import map_coordinates, gaussian_filter

            def elastic_transform(image, alpha=30, sigma=5):
                shape = image.shape
                dx = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha
                dy = gaussian_filter((np.random.rand(*shape) * 2 - 1), sigma) * alpha

                x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))
                indices = np.reshape(y + dy, (-1, 1)), np.reshape(x + dx, (-1, 1))

                return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)

            ct_img = elastic_transform(ct_img)
            ct_mask = elastic_transform(ct_mask)
            ct_prior = elastic_transform(ct_prior)
            mri_img = elastic_transform(mri_img)
            mri_mask = elastic_transform(mri_mask)
            mri_prior = elastic_transform(mri_prior)

        # 5. é«˜æ–¯å™ªå£°ï¼ˆ40%æ¦‚ç‡ï¼Œé™ä½å¼ºåº¦ï¼‰
        if random.random() > 0.6:
            noise_std = random.uniform(0.005, 0.015)  # ğŸ”¥ é™ä½å™ªå£°
            ct_img = np.clip(ct_img + np.random.randn(*ct_img.shape) * noise_std, 0, 1)
            mri_img = np.clip(mri_img + np.random.randn(*mri_img.shape) * noise_std, 0, 1)

        # 6. å¯¹æ¯”åº¦è°ƒæ•´ï¼ˆ30%æ¦‚ç‡ï¼‰
        if random.random() > 0.7:
            gamma = random.uniform(0.85, 1.15)  # ğŸ”¥ æ›´æ¸©å’Œçš„gamma
            ct_img = np.power(ct_img, gamma)
            mri_img = np.power(mri_img, gamma)

        # ğŸ”¥ 7. éšæœºäº®åº¦è°ƒæ•´ï¼ˆæ–°å¢ï¼Œ30%æ¦‚ç‡ï¼‰
        if random.random() > 0.7:
            brightness = random.uniform(0.9, 1.1)
            ct_img = np.clip(ct_img * brightness, 0, 1)
            mri_img = np.clip(mri_img * brightness, 0, 1)

        return ct_img, ct_mask, mri_img, mri_mask, ct_prior, mri_prior




def create_mmwhs_loaders(data_root, batch_size=4, num_workers=4, pin_memory=True, prefetch_factor=2):
    """
    åˆ›å»ºMMWHSæ•°æ®åŠ è½½å™¨

    è¿”å›æ ¼å¼ä¸åŸä»£ç ä¸€è‡´ï¼štrain_loader, val_loader
    """

    # è®­ç»ƒé›†ï¼ˆå¸¦æ•°æ®å¢å¼ºï¼‰
    train_dataset = MMWHSDataset(
        data_root=data_root,
        split='train',
        augment=True
    )

    # éªŒè¯é›†ï¼ˆä¸å¢å¼ºï¼‰
    val_dataset = MMWHSDataset(
        data_root=data_root,
        split='val',
        augment=False
    )

    # åˆ›å»ºDataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        prefetch_factor=prefetch_factor if num_workers > 0 else None,
        persistent_workers=True if num_workers > 0 else False
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=1,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        prefetch_factor=prefetch_factor if num_workers > 0 else None,
        persistent_workers=True if num_workers > 0 else False
    )

    print(f"\næ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆ:")
    print(f"  è®­ç»ƒé›†: {len(train_dataset)} æ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(val_dataset)} æ ·æœ¬")
    print(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")

    return train_loader, val_loader


# æµ‹è¯•ä»£ç 
if __name__ == '__main__':
    data_root = r'D:\AåŸºäºUNetå®ç°å¤šæ¨¡æ€è·¨åŸŸè‡ªé€‚åº”\unet\Pytorch-UNet-master\data\mmwhs_processed'

    train_loader, val_loader = create_mmwhs_loaders(data_root, batch_size=2)

    # âœ… ä¿®æ”¹æµ‹è¯•éƒ¨åˆ†
    print("\næµ‹è¯•æ•°æ®åŠ è½½:")
    for batch in train_loader:
        ct_img = batch['ct_image']
        ct_mask = batch['ct_mask']
        mri_img = batch['mri_image']
        mri_mask = batch['mri_mask']

        print(f"  CTå›¾åƒ: {ct_img.shape}, èŒƒå›´: [{ct_img.min():.3f}, {ct_img.max():.3f}]")
        print(f"  CTæ ‡æ³¨: {ct_mask.shape}, ç±»åˆ«: {torch.unique(ct_mask)}")
        print(f"  MRå›¾åƒ: {mri_img.shape}, èŒƒå›´: [{mri_img.min():.3f}, {mri_img.max():.3f}]")
        print(f"  MRæ ‡æ³¨: {mri_mask.shape}, ç±»åˆ«: {torch.unique(mri_mask)}")
        break